{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10.710864418838396\n",
      "Predicted MPG for the example input: 21.385639953053804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "df = pd.read_csv(url, delim_whitespace=True, names=column_names)\n",
    "\n",
    "# Preprocess the data\n",
    "df.drop('car_name', axis=1, inplace=True)  # Drop the 'car_name' column\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')  # Convert 'horsepower' to numeric, handle errors\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('mpg', axis=1)\n",
    "y = df['mpg']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Example prediction\n",
    "example_input = [[6, 225, 100, 3233, 15.4, 76, 1]]  # Example input data for prediction\n",
    "example_input_scaled = scaler.transform(example_input)\n",
    "predicted_mpg = model.predict(example_input_scaled)\n",
    "print(f'Predicted MPG for the example input: {predicted_mpg[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 - 1s - loss: 604.7418 - val_loss: 540.3815 - 842ms/epoch - 84ms/step\n",
      "Epoch 2/50\n",
      "10/10 - 0s - loss: 576.9014 - val_loss: 512.5603 - 49ms/epoch - 5ms/step\n",
      "Epoch 3/50\n",
      "10/10 - 0s - loss: 548.0155 - val_loss: 481.1074 - 52ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "10/10 - 0s - loss: 513.8058 - val_loss: 443.3564 - 46ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "10/10 - 0s - loss: 470.8144 - val_loss: 397.4907 - 46ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "10/10 - 0s - loss: 418.7661 - val_loss: 341.1951 - 42ms/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "10/10 - 0s - loss: 354.8402 - val_loss: 277.2886 - 43ms/epoch - 4ms/step\n",
      "Epoch 8/50\n",
      "10/10 - 0s - loss: 284.6585 - val_loss: 210.0183 - 42ms/epoch - 4ms/step\n",
      "Epoch 9/50\n",
      "10/10 - 0s - loss: 211.6952 - val_loss: 146.5094 - 41ms/epoch - 4ms/step\n",
      "Epoch 10/50\n",
      "10/10 - 0s - loss: 146.1469 - val_loss: 94.3847 - 48ms/epoch - 5ms/step\n",
      "Epoch 11/50\n",
      "10/10 - 0s - loss: 95.2862 - val_loss: 60.3916 - 41ms/epoch - 4ms/step\n",
      "Epoch 12/50\n",
      "10/10 - 0s - loss: 62.2983 - val_loss: 46.0313 - 43ms/epoch - 4ms/step\n",
      "Epoch 13/50\n",
      "10/10 - 0s - loss: 47.9970 - val_loss: 42.1462 - 44ms/epoch - 4ms/step\n",
      "Epoch 14/50\n",
      "10/10 - 0s - loss: 41.7891 - val_loss: 39.6469 - 44ms/epoch - 4ms/step\n",
      "Epoch 15/50\n",
      "10/10 - 0s - loss: 38.0851 - val_loss: 36.7377 - 47ms/epoch - 5ms/step\n",
      "Epoch 16/50\n",
      "10/10 - 0s - loss: 34.2458 - val_loss: 33.1644 - 44ms/epoch - 4ms/step\n",
      "Epoch 17/50\n",
      "10/10 - 0s - loss: 30.8459 - val_loss: 29.9408 - 49ms/epoch - 5ms/step\n",
      "Epoch 18/50\n",
      "10/10 - 0s - loss: 27.9637 - val_loss: 27.5478 - 40ms/epoch - 4ms/step\n",
      "Epoch 19/50\n",
      "10/10 - 0s - loss: 25.5554 - val_loss: 25.5514 - 47ms/epoch - 5ms/step\n",
      "Epoch 20/50\n",
      "10/10 - 0s - loss: 23.5514 - val_loss: 23.8536 - 42ms/epoch - 4ms/step\n",
      "Epoch 21/50\n",
      "10/10 - 0s - loss: 21.9341 - val_loss: 22.2225 - 44ms/epoch - 4ms/step\n",
      "Epoch 22/50\n",
      "10/10 - 0s - loss: 20.3832 - val_loss: 20.8820 - 42ms/epoch - 4ms/step\n",
      "Epoch 23/50\n",
      "10/10 - 0s - loss: 19.0835 - val_loss: 19.7005 - 40ms/epoch - 4ms/step\n",
      "Epoch 24/50\n",
      "10/10 - 0s - loss: 18.0761 - val_loss: 18.6584 - 41ms/epoch - 4ms/step\n",
      "Epoch 25/50\n",
      "10/10 - 0s - loss: 17.1093 - val_loss: 17.6527 - 40ms/epoch - 4ms/step\n",
      "Epoch 26/50\n",
      "10/10 - 0s - loss: 16.2552 - val_loss: 16.8866 - 41ms/epoch - 4ms/step\n",
      "Epoch 27/50\n",
      "10/10 - 0s - loss: 15.5459 - val_loss: 16.1154 - 42ms/epoch - 4ms/step\n",
      "Epoch 28/50\n",
      "10/10 - 0s - loss: 14.8466 - val_loss: 15.4642 - 42ms/epoch - 4ms/step\n",
      "Epoch 29/50\n",
      "10/10 - 0s - loss: 14.3435 - val_loss: 14.8031 - 46ms/epoch - 5ms/step\n",
      "Epoch 30/50\n",
      "10/10 - 0s - loss: 13.8038 - val_loss: 14.3725 - 45ms/epoch - 4ms/step\n",
      "Epoch 31/50\n",
      "10/10 - 0s - loss: 13.3800 - val_loss: 13.8974 - 43ms/epoch - 4ms/step\n",
      "Epoch 32/50\n",
      "10/10 - 0s - loss: 12.9874 - val_loss: 13.4496 - 44ms/epoch - 4ms/step\n",
      "Epoch 33/50\n",
      "10/10 - 0s - loss: 12.6379 - val_loss: 13.2010 - 40ms/epoch - 4ms/step\n",
      "Epoch 34/50\n",
      "10/10 - 0s - loss: 12.3236 - val_loss: 12.8276 - 48ms/epoch - 5ms/step\n",
      "Epoch 35/50\n",
      "10/10 - 0s - loss: 12.0712 - val_loss: 12.5097 - 51ms/epoch - 5ms/step\n",
      "Epoch 36/50\n",
      "10/10 - 0s - loss: 11.7640 - val_loss: 12.2139 - 40ms/epoch - 4ms/step\n",
      "Epoch 37/50\n",
      "10/10 - 0s - loss: 11.5286 - val_loss: 11.8378 - 44ms/epoch - 4ms/step\n",
      "Epoch 38/50\n",
      "10/10 - 0s - loss: 11.2746 - val_loss: 11.6575 - 45ms/epoch - 4ms/step\n",
      "Epoch 39/50\n",
      "10/10 - 0s - loss: 11.1074 - val_loss: 11.5280 - 45ms/epoch - 4ms/step\n",
      "Epoch 40/50\n",
      "10/10 - 0s - loss: 10.9207 - val_loss: 11.3069 - 40ms/epoch - 4ms/step\n",
      "Epoch 41/50\n",
      "10/10 - 0s - loss: 10.7353 - val_loss: 11.0024 - 42ms/epoch - 4ms/step\n",
      "Epoch 42/50\n",
      "10/10 - 0s - loss: 10.6194 - val_loss: 10.7938 - 43ms/epoch - 4ms/step\n",
      "Epoch 43/50\n",
      "10/10 - 0s - loss: 10.4323 - val_loss: 10.7650 - 44ms/epoch - 4ms/step\n",
      "Epoch 44/50\n",
      "10/10 - 0s - loss: 10.3291 - val_loss: 10.5736 - 43ms/epoch - 4ms/step\n",
      "Epoch 45/50\n",
      "10/10 - 0s - loss: 10.1453 - val_loss: 10.4415 - 40ms/epoch - 4ms/step\n",
      "Epoch 46/50\n",
      "10/10 - 0s - loss: 9.9875 - val_loss: 10.3219 - 43ms/epoch - 4ms/step\n",
      "Epoch 47/50\n",
      "10/10 - 0s - loss: 9.9080 - val_loss: 10.2289 - 43ms/epoch - 4ms/step\n",
      "Epoch 48/50\n",
      "10/10 - 0s - loss: 9.8141 - val_loss: 9.9443 - 41ms/epoch - 4ms/step\n",
      "Epoch 49/50\n",
      "10/10 - 0s - loss: 9.6896 - val_loss: 9.9087 - 44ms/epoch - 4ms/step\n",
      "Epoch 50/50\n",
      "10/10 - 0s - loss: 9.5825 - val_loss: 9.8039 - 40ms/epoch - 4ms/step\n",
      "Mean Squared Error: 9.803919464475918\n",
      "Predicted MPG for the example input: 15.938576698303223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# workaround for a Jupyter notebook error when importing tf.keras.models\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "df = pd.read_csv(url, delim_whitespace=True, names=column_names)\n",
    "\n",
    "# Preprocess the data\n",
    "df.drop('car_name', axis=1, inplace=True)\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('mpg', axis=1)\n",
    "y = df['mpg']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Example prediction\n",
    "example_input = np.array([[6, 225, 100, 3233, 15.4, 76, 1]])  # Example input data for prediction\n",
    "example_input_scaled = scaler.transform(example_input)\n",
    "predicted_mpg = model.predict(example_input_scaled)\n",
    "print(f'Predicted MPG for the example input: {predicted_mpg[0][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
